
# -*- coding: utf-8 -*-
"""
Script para corrigir problemas de codifica√ß√£o no arquivo ToLD-BR.csv
Corrige caracteres que foram mal codificados (UTF-8 lido como Latin-1/Windows-1252)
"""

import pandas as pd
import re
from pathlib import Path

def detect_encoding(file_path):
    """Tenta detectar a codifica√ß√£o do arquivo testando diferentes encodings"""
    encodings_to_try = ['utf-8', 'latin-1', 'cp1252', 'iso-8859-1']
    
    for encoding in encodings_to_try:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                f.read(1000)  # L√™ apenas os primeiros 1000 caracteres para testar
            return encoding
        except (UnicodeDecodeError, UnicodeError):
            continue
    
    return 'utf-8'  # Fallback para UTF-8

def fix_encoding_issues(text):
    """
    Corrige problemas de codifica√ß√£o comuns em texto portugu√™s
    """
    if pd.isna(text) or not isinstance(text, str):
        return text
    
    # Dicion√°rio de corre√ß√µes para caracteres mal codificados
    corrections = {
        # Acentos e caracteres especiais b√°sicos
        'Èîö': '√™',  # √™ mal codificado
        'Ëå´': '√£',  # √£ mal codificado
        'ÈìÜ': '√≠',  # √≠ mal codificado
        'Ë∞©': '√°',  # √° mal codificado
        'Ë¥∏': '√≥',  # √≥ mal codificado
        'ËåÖ': '√©',  # √© mal codificado
        'ËéΩ': '√ß',  # √ß mal codificado
        'ËÑø': '√†',  # √† mal codificado
        '‰πà': '√£',  # √£ mal codificado
        'ÁÖ§': '√∫',  # √∫ mal codificado
        'Áé´': '√©',  # √© mal codificado
        'Èà•': '‚Ä¶',  # retic√™ncias mal codificadas
        'È¶ÉÊÜ°': 'üòÑ',  # emoji sorriso
        'È¶ÉÂöô': 'üòç',  # emoji apaixonado
        'È¶ÉÂö™': 'üòä',  # emoji sorriso t√≠mido
        'È¶ÉÊ£è': 'üò≠',  # emoji chorando
        'È¶ÉÂèû': 'üòÖ',  # emoji suando
        'È¶ÉÊß´': 'üò≠',  # emoji chorando (outra varia√ß√£o)
        'È¶ÉÊßÄ': 'üòÇ',  # emoji rindo (outra varia√ß√£o)
        'ÈîîÂø¶ÁÑªÂ∏ÆÁ¨ç': 'üòÇ',  # emoji rindo (sequ√™ncia mal codificada)
        
        # Corre√ß√µes adicionais do notebook
        'Ëäí': '√¢',  # √¢ mal codificado
        '‰πà': '√¥',  # √¥ mal codificado
        'Áé´': '√µ',  # √µ mal codificado
        'ËÑ≥': 'x',  # x mal codificado
        'ËÑ°': '√â',  # √â mal codificado
        'ËÑ•': '√ç',  # √ç mal codificado
        'ËÑô': '√É',  # √É mal codificado
        'ËÅΩ': ' ',  # espa√ßo mal codificado
        'Ê∑•': 'O',  # O mal codificado
        'Ê∏â': 'H',  # H mal codificado
        'Ê∏É': 'C',  # C mal codificado
        'Ê∏õ': 'C',  # C mal codificado
        'Ê•§': 'B',  # B mal codificado
        'ËÑü': '√á',  # √á mal codificado
        'ËÑ≠': '√î',  # √î mal codificado
        'ËÑï': '√Å',  # √Å mal codificado
        'ËÑó': '√Ç',  # √Ç mal codificado
        'Èôã': '¬™',  # ¬™ mal codificado
        
        # Caracteres adicionais detectados automaticamente
        'È¶É': '',  # emoji mal codificado
        '"': '"',  # aspas inteligentes
        '"': '"',  # aspas inteligentes
        '‚Äç': '',   # zero width joiner
        '': '',   # replacement character
        '¬∞': '¬∞',  # grau
        ' ': ' ',  # non-breaking space
        '¬∫': '¬∫',  # ordinal masculino
        'Èîî': '',  # caractere mal codificado
        'Â∂Å': '',  # caractere mal codificado
        'Êßè': '',  # caractere mal codificado
        '\u2019': "'",  # apostrofe inteligente
        'Á¨ç': '',  # caractere mal codificado
        'ÈâÇ': '',  # caractere mal codificado
        'Âæì': '',  # caractere mal codificado
        'Ê™ß': '',  # caractere mal codificado
        'ÈâÅ': '',  # caractere mal codificado
        'Âñî': '',  # caractere mal codificado
        'Ê™Æ': '',  # caractere mal codificado
        'Êß∂': '',  # caractere mal codificado
        'Êß®': '',  # caractere mal codificado
        
        # Caracteres problem√°ticos adicionais encontrados
        'Ê™ö': '',  # caractere CJK problem√°tico
        'Â¥ô': '',  # caractere CJK problem√°tico
        'Êßá': '',  # caractere CJK problem√°tico
        'Â¥ã': '',  # caractere CJK problem√°tico
        'Êïü': '',  # caractere CJK problem√°tico
        'Áå¨': '',  # caractere CJK problem√°tico
        'Âõ∑': '',  # caractere CJK problem√°tico
        '„ÅÑ': '',   # hiragana
        'Â¥ù': '',  # caractere CJK problem√°tico
        'Â¥Ø': '',  # caractere CJK problem√°tico
        'ÊÜ§': '',  # caractere CJK problem√°tico
        'Âæè': '',  # caractere CJK problem√°tico
        'Êßí': '',  # caractere CJK problem√°tico
        'Êßã': '',  # caractere CJK problem√°tico
        'ÊÜñ': '',  # caractere CJK problem√°tico
        '„Çè': '',  # hiragana
        'Âµì': '',  # caractere CJK problem√°tico
        'Êå¶': '',  # caractere CJK problem√°tico
        'Êïí': '',  # caractere CJK problem√°tico
        'Êã´': '',  # caractere CJK problem√°tico
        'ÊåÖ': '',  # caractere CJK problem√°tico
        'ÊÜõ': '',  # caractere CJK problem√°tico
        'Êåú': '',  # caractere CJK problem√°tico
        'ÊåÑ': '',  # caractere CJK problem√°tico
        
        # Caracteres problem√°ticos adicionais encontrados
        '„Ç≥': '',  # katakana problem√°tico
        'Êåµ': '',  # caractere CJK problem√°tico
        'ÊÜ¶': '',  # caractere CJK problem√°tico
        'ÂπÅ': '',  # caractere CJK problem√°tico
    }
    
    # Aplicar corre√ß√µes
    for wrong, correct in corrections.items():
        text = text.replace(wrong, correct)
    
    # Corrigir sequ√™ncias de emojis mal codificadas
    # Padr√£o para emojis que foram quebrados em m√∫ltiplos caracteres
    emoji_patterns = [
        (r'È¶ÉÂèûÈîîÂø¶ÁÑªÂ∏ÆÁ¨ç', 'üòÇ'),  # emoji rindo simples
    ]
    
    for pattern, replacement in emoji_patterns:
        text = re.sub(pattern, replacement, text)
    
    # Limpeza sistem√°tica de caracteres CJK problem√°ticos
    # Substituir todos os caracteres CJK por ?
    text = re.sub(r'[\u4E00-\u9FFF]', '', text)  # Caracteres CJK
    text = re.sub(r'[\uAC00-\uD7AF]', '', text)  # Hangul
    text = re.sub(r'[\u3040-\u309F]', '', text)   # Hiragana (remover)
    text = re.sub(r'[\u30A0-\u30FF]', '', text)  # Katakana
    
    # Remover todas as men√ß√µes @user
    text = re.sub(r'@user\b', '', text)  # Remove @user
    text = re.sub(r'@\w+\b', '', text)   # Remove qualquer @men√ß√£o
    
    # Remover todas as palavras "rt"
    text = re.sub(r'\brt\b', '', text)  # Remove "rt" como palavra completa
    
    # Remover caracteres de substitui√ß√£o
    text = text.replace('ÔøΩ', '')  # Remove caracteres de substitui√ß√£o
    
    # Limpar espa√ßos extras que podem ter sobrado
    #text = re.sub(r'\s+', ' ', text)  # M√∫ltiplos espa√ßos para um s√≥
    #text = text.strip()  # Remover espa√ßos no in√≠cio e fim
    
    return text

def apply_double_encoding_fix(text):
    """
    Aplica a t√©cnica de re-encoding: encode('latin1').decode('utf-8')
    Esta t√©cnica √© muito eficaz para corrigir problemas de codifica√ß√£o dupla
    """
    if pd.isna(text) or not isinstance(text, str):
        return text
    
    try:
        # Aplicar a t√©cnica de re-encoding
        # Isso corrige casos onde UTF-8 foi lido como Latin-1 e vice-versa
        fixed_text = text.encode('latin1').decode('utf-8')
        return fixed_text
    except (UnicodeEncodeError, UnicodeDecodeError):
        # Se der erro, retorna o texto original
        return text
    except Exception:
        # Qualquer outro erro, retorna o texto original
        return text

def fix_encoding_issues_with_reencoding(text):
    """
    Corrige problemas de codifica√ß√£o usando substitui√ß√µes + re-encoding
    """
    if pd.isna(text) or not isinstance(text, str):
        return text
    
    # Primeiro, aplicar as corre√ß√µes manuais
    text = fix_encoding_issues(text)
    
    # Depois, aplicar a t√©cnica de re-encoding
    text = apply_double_encoding_fix(text)
    
    return text

def fix_csv_encoding(input_file, output_file=None):
    """
    Corrige problemas de codifica√ß√£o em um arquivo CSV
    """
    if output_file is None:
        output_file = input_file.replace('.csv', '_fixed.csv')
    
    print(f"Detectando codifica√ß√£o do arquivo: {input_file}")
    
    # Detectar codifica√ß√£o
    encoding = detect_encoding(input_file)
    print(f"Codifica√ß√£o detectada: {encoding}")
    
    # Ler o arquivo com a codifica√ß√£o detectada
    try:
        df = pd.read_csv(input_file, encoding=encoding)
        print(f"Arquivo lido com sucesso. Shape: {df.shape}")
    except Exception as e:
        print(f"Erro ao ler com codifica√ß√£o detectada: {e}")
        # Tentar com UTF-8
        try:
            df = pd.read_csv(input_file, encoding='utf-8')
            print("Arquivo lido com UTF-8")
        except:
            # Tentar com Latin-1
            df = pd.read_csv(input_file, encoding='latin-1')
            print("Arquivo lido com Latin-1")
    
    print("Aplicando corre√ß√µes de codifica√ß√£o...")
    
    # Aplicar corre√ß√µes na coluna de texto (com re-encoding)
    if 'text' in df.columns:
        df['text'] = df['text'].apply(fix_encoding_issues_with_reencoding)
        print("Corre√ß√µes aplicadas na coluna 'text' (incluindo re-encoding)")
    
    # Salvar arquivo corrigido
    df.to_csv(output_file, index=False, encoding='utf-8')
    print(f"Arquivo corrigido salvo como: {output_file}")
    
    return df

def main():
    """Fun√ß√£o principal"""
    input_file = "ToLD-BR.csv"
    output_file = "ToLD-BR_fixed.csv"
    
    print("=== Corretor de Codifica√ß√£o ToLD-BR ===")
    print(f"Arquivo de entrada: {input_file}")
    print(f"Arquivo de sa√≠da: {output_file}")
    print()
    
    # Verificar se o arquivo existe
    if not Path(input_file).exists():
        print(f"ERRO: Arquivo {input_file} n√£o encontrado!")
        return
    
    # Corrigir codifica√ß√£o
    try:
        df_fixed = fix_csv_encoding(input_file, output_file)
        
        print("\n=== Exemplos de corre√ß√µes ===")
        # Mostrar alguns exemplos de corre√ß√µes
        if 'text' in df_fixed.columns:
            # Procurar por linhas que tinham problemas de codifica√ß√£o
            problematic_rows = df_fixed[df_fixed['text'].str.contains('√™|√£|√≠|√°|√≥|√©|√ß|√†|üòÑ|üòç|üòä|üò≠|üòÖ|üòÇ', na=False)]
            
            if len(problematic_rows) > 0:
                print("Algumas linhas corrigidas:")
                for i, row in problematic_rows.head(3).iterrows():
                    print(f"Linha {i}: {row['text'][:100]}...")
            else:
                print("Nenhuma linha com problemas de codifica√ß√£o encontrada.")
        
        print(f"\nArquivo corrigido salvo com sucesso!")
        print(f"Total de linhas processadas: {len(df_fixed)}")
        
    except Exception as e:
        print(f"ERRO durante o processamento: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
